# üîó Experimental CMDB

> **A modern Configuration Management Database (CMDB) concept application showcasing next-generation IT infrastructure management capabilities**

![Architecture](https://img.shields.io/badge/Architecture-Graph--Based-blue)
![Database](https://img.shields.io/badge/Database-Neo4j-green)
![Backend](https://img.shields.io/badge/Backend-Node.js-brightgreen)
![License](https://img.shields.io/badge/License-MIT-yellow)

## üìã Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Architecture](#-architecture)
- [Demo Objectives](#-demo-objectives)
- [Installation](#-installation)
- [Usage Guide](#-usage-guide)
- [API Reference](#-api-reference)
- [Technical Details](#-technical-details)
- [Development](#-development)
- [Testing](#-testing)
- [Performance](#-performance)
- [Security](#-security)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)

## üéØ Overview

The Experimental CMDB is a cutting-edge proof-of-concept that demonstrates how modern technologies can revolutionize Configuration Management Database systems. Built with graph database technology at its core, this application showcases the power of relationship-centric data modeling for IT infrastructure management.

### **Why This Matters**

Traditional CMDBs struggle with:
- Complex relationship modeling in SQL databases
- Performance degradation on multi-hop dependency queries
- Inflexible schemas that can't adapt to evolving infrastructure
- Limited real-time correlation capabilities

This experimental CMDB addresses these challenges by leveraging:
- **Graph Database Technology** (Neo4j) for natural relationship modeling
- **AI-Driven Correlation** for intelligent event analysis
- **Real-time Processing** with WebSocket integration
- **Scalable Architecture** with distributed worker processing

## ‚ú® Key Features

### üèóÔ∏è **Infrastructure Management**
- **Configuration Items (CIs)**: Servers, applications, databases, network devices
- **Dynamic Relationships**: DEPENDS_ON, RUNS_ON, HOSTED_IN, SUPPORTS, AFFECTS
- **Real-time Discovery**: Automated CI relationship detection
- **Health Monitoring**: Comprehensive status tracking and alerting

### üß† **AI-Powered Analytics**
- **Event Correlation Engine**: Time-based and topology-aware correlation
- **Pattern Recognition**: Historical pattern analysis for predictive insights
- **Root Cause Analysis**: Topology-aware incident investigation
- **Business Impact Assessment**: Service-centric impact analysis with revenue calculations

### üìä **Visualization & Monitoring**
- **Interactive Topology Maps**: D3.js-powered network visualization
- **Real-time Dashboards**: Live metrics and performance monitoring
- **Dependency Mapping**: Multi-hop relationship traversal
- **Impact Analysis**: Visual blast radius calculations

### ‚ö° **Performance & Scalability**
- **Distributed Processing**: Bull queue-based job processing
- **Scalable Data Generation**: Enterprise-scale test data (50,000+ CIs)
- **Real-time Updates**: WebSocket-based live data streaming
- **Optimized Queries**: Efficient Cypher queries with batching

### üîí **Enterprise Features**
- **Business Service Mapping**: Revenue impact tracking
- **Multi-environment Support**: Production, staging, development
- **Audit Trail**: Comprehensive change tracking
- **Role-based Access**: (Planned for future releases)

## üèõÔ∏è Architecture

### **System Overview**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Web Browser   ‚îÇ    ‚îÇ   Mobile Apps   ‚îÇ    ‚îÇ  External APIs  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                      ‚îÇ                      ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ      Load Balancer         ‚îÇ
                    ‚îÇ      (Future)              ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    Node.js Express API     ‚îÇ
                    ‚îÇ    ‚Ä¢ REST Endpoints        ‚îÇ
                    ‚îÇ    ‚Ä¢ WebSocket Server      ‚îÇ
                    ‚îÇ    ‚Ä¢ Authentication        ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ                      ‚îÇ                      ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Neo4j Graph   ‚îÇ    ‚îÇ   Redis Cache   ‚îÇ    ‚îÇ  Worker Nodes   ‚îÇ
‚îÇ   Database      ‚îÇ    ‚îÇ   ‚Ä¢ Sessions    ‚îÇ    ‚îÇ  ‚Ä¢ Data Gen     ‚îÇ
‚îÇ   ‚Ä¢ CIs         ‚îÇ    ‚îÇ   ‚Ä¢ Queue       ‚îÇ    ‚îÇ  ‚Ä¢ Correlation  ‚îÇ
‚îÇ   ‚Ä¢ Events      ‚îÇ    ‚îÇ   ‚Ä¢ Real-time   ‚îÇ    ‚îÇ  ‚Ä¢ Processing   ‚îÇ
‚îÇ   ‚Ä¢ Services    ‚îÇ    ‚îÇ     Data        ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Component Architecture**

#### **Frontend Layer**
- **Technology**: Vanilla JavaScript, HTML5, CSS3
- **Visualization**: D3.js for interactive graphs
- **Real-time**: Socket.IO client for live updates
- **UI Framework**: Custom responsive design

#### **API Layer**
- **Framework**: Node.js with Express.js
- **Authentication**: JWT-based (planned)
- **Middleware**: CORS, compression, rate limiting
- **Documentation**: OpenAPI/Swagger integration (planned)

#### **Data Layer**
- **Primary Database**: Neo4j Graph Database
- **Cache Layer**: Redis for sessions and real-time data
- **Message Queue**: Bull.js with Redis backend
- **File Storage**: Local filesystem (cloud storage planned)

#### **Processing Layer**
- **Background Workers**: Distributed job processing
- **Correlation Engine**: Real-time event analysis
- **Data Generation**: Scalable test data creation
- **Monitoring**: Winston logging with structured output

## üéÆ Demo Objectives

This experimental CMDB is designed to demonstrate several key concepts:

### **1. Graph Database Advantages**
**Objective**: Show how graph databases excel at relationship queries compared to SQL

**Demo Features**:
- **Multi-hop Dependency Analysis**: Query 6+ levels deep in milliseconds
- **Variable-depth Traversal**: Simple parameter changes vs complex SQL rewrites
- **Performance Comparison**: Side-by-side Cypher vs SQL query examples
- **Real-time Impact Analysis**: Instant blast radius calculations

**Business Value**:
- 50x faster complex dependency queries
- Intuitive relationship modeling
- Real-time operational decision making

### **2. AI-Driven Event Correlation**
**Objective**: Demonstrate intelligent event correlation using graph algorithms

**Demo Features**:
- **Time-based Correlation**: Events within temporal windows
- **Topology-aware Analysis**: Relationship-based event linking
- **Pattern Recognition**: Historical correlation patterns
- **Business Impact Mapping**: Revenue-at-risk calculations

**Business Value**:
- Reduced MTTR (Mean Time To Resolution)
- Proactive incident management
- Automated root cause analysis

### **3. Enterprise Scalability**
**Objective**: Prove the system can handle enterprise-scale data

**Demo Features**:
- **Large Dataset Generation**: 50,000+ CIs with complex relationships
- **Real-time Processing**: Live updates with minimal latency
- **Distributed Architecture**: Horizontal scaling capabilities
- **Performance Monitoring**: Real-time metrics and dashboards

**Business Value**:
- Enterprise-ready architecture
- Linear scaling with data growth
- Production-grade reliability

### **4. Modern DevOps Integration**
**Objective**: Show integration with modern IT operations workflows

**Demo Features**:
- **API-First Design**: RESTful APIs for all operations
- **Real-time Monitoring**: Live dashboards and alerting
- **Containerized Deployment**: Docker-based architecture
- **Infrastructure as Code**: Declarative configuration

**Business Value**:
- Seamless tool integration
- Modern deployment practices
- Reduced operational overhead

## üöÄ Installation

### **Prerequisites**

- **Docker & Docker Compose**: v20.10+ and v2.0+
- **Node.js**: v18+ (for local development)
- **Git**: Latest version
- **System Requirements**:
  - RAM: 8GB minimum (16GB recommended)
  - Storage: 10GB free space
  - CPU: 4 cores minimum (8 cores recommended)

### **Quick Start (Recommended)**

1. **Clone the repository**:
   ```bash
   git clone https://github.com/your-org/experimental-cmdb.git
   cd experimental-cmdb
   ```

2. **Configure environment**:
   ```bash
   cp .env.example .env
   # Edit .env with your settings (see Configuration section)
   ```

3. **Start the application**:
   ```bash
   docker-compose up -d
   ```

4. **Verify installation**:
   ```bash
   # Check all services are running
   docker-compose ps

   # Test API health
   curl http://localhost:3000/health
   ```

5. **Access the application**:
   - **Web Application**: http://localhost:3000
   - **Neo4j Browser**: http://localhost:7474
   - **API Documentation**: http://localhost:3000/api-docs (planned)

### **Development Setup**

For local development without Docker:

1. **Install dependencies**:
   ```bash
   npm install
   ```

2. **Start Neo4j**:
   ```bash
   # Using Docker
   docker run --name neo4j \
     -p 7474:7474 -p 7687:7687 \
     -e NEO4J_AUTH=neo4j/password \
     neo4j:latest

   # Or install locally from https://neo4j.com/download/
   ```

3. **Start Redis**:
   ```bash
   # Using Docker
   docker run --name redis -p 6379:6379 redis:latest

   # Or install locally
   brew install redis  # macOS
   sudo apt-get install redis  # Ubuntu
   ```

4. **Start the application**:
   ```bash
   npm run dev  # Development mode with auto-reload
   npm start    # Production mode
   ```

### **Configuration**

#### **Environment Variables**

Create and configure your `.env` file:

```bash
# Database Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_secure_password_here

# Redis Configuration
REDIS_URL=redis://localhost:6379

# Application Configuration
PORT=3000
NODE_ENV=development

# Worker Configuration
WORKER_CONCURRENCY=3
APP_SERVER_URL=http://app:3000

# Security (Production)
JWT_SECRET=your_jwt_secret_here
SESSION_SECRET=your_session_secret_here
```

#### **Docker Compose Configuration**

The `docker-compose.yml` includes:
- **Web Application**: Main Node.js server
- **Neo4j Database**: Graph database with web browser
- **Redis**: Cache and message queue
- **Workers**: Background processing nodes

#### **Production Configuration**

For production deployments:

1. **Use strong passwords** for all database connections
2. **Enable TLS/SSL** for all network communications
3. **Configure proper logging** with log aggregation
4. **Set up monitoring** with health checks
5. **Use secrets management** (HashiCorp Vault, AWS Secrets Manager)

## üìñ Usage Guide

### **Getting Started**

1. **Access the Web Interface**: Navigate to http://localhost:3000

2. **Overview Dashboard**:
   - View database statistics
   - Monitor system health
   - Check recent activity

3. **Generate Sample Data**:
   - Go to "Data Generation" tab
   - Select a scale (Sample, Medium, Large, Enterprise)
   - Click "Start Data Generation"
   - Monitor progress in real-time

### **Core Workflows**

#### **1. Exploring the Topology**

```bash
# Navigate to Topology tab
# Filter by component type (Servers, Databases, etc.)
# Zoom and pan to explore relationships
# Click nodes to view details
```

#### **2. Simulating Events**

```bash
# Go to Events tab
# Click "Simulate Single Event" for random events
# Use "Create Sample Incident" for correlated events
# Try "Simulate Cascade Failure" for complex scenarios
```

#### **3. Running Correlation Analysis**

```bash
# Switch to Correlation tab
# Ensure you have events (use Events tab to create them)
# Click "Run Analysis" to analyze correlations
# View business impact and patterns
```

#### **4. Impact Analysis Demo**

```bash
# Go to Demo tab
# Select a pre-configured scenario or choose custom component
# Set analysis depth (1-6 hops)
# Click "Run Impact Analysis"
# Review dependency chains and business impact
# Compare Cypher vs SQL query complexity
```

### **Advanced Features**

#### **Real-time Monitoring**
- Enable debug console (bottom panel) for live operation monitoring
- Use browser developer tools to inspect WebSocket messages
- Monitor worker progress during data generation

#### **Custom Data Generation**
- Modify scale configurations in code
- Add custom CI types and relationships
- Implement custom event templates

#### **API Integration**
- Use REST APIs for custom integrations
- Implement webhooks for external event ingestion
- Build custom dashboards using the API

## üìö API Reference

### **Core Endpoints**

#### **CMDB Management**
```http
GET    /api/cmdb/items              # List configuration items
POST   /api/cmdb/items              # Create new CI
GET    /api/cmdb/items/:id          # Get CI details
PUT    /api/cmdb/items/:id          # Update CI
DELETE /api/cmdb/items/:id          # Delete CI
GET    /api/cmdb/topology           # Get topology data
GET    /api/cmdb/impact/:id         # Run impact analysis
```

#### **Event Management**
```http
GET    /api/events                  # List events
POST   /api/events                  # Create event
PUT    /api/events/:id              # Update event
DELETE /api/events/:id              # Delete event
GET    /api/events/stats            # Event statistics
POST   /api/events/simulate         # Simulate random event
DELETE /api/events/clear            # Clear all events
```

#### **Correlation Engine**
```http
GET    /api/correlation/analyze     # Run correlation analysis
GET    /api/correlation/patterns    # Get correlation patterns
GET    /api/correlation/business-impact  # Business impact analysis
```

#### **Data Generation**
```http
GET    /api/jobs                    # List generation jobs
POST   /api/jobs                    # Start new generation job
GET    /api/jobs/:id                # Get job status
DELETE /api/jobs/:id               # Cancel job
GET    /api/jobs/scales             # Available data scales
```

#### **Demo Features**
```http
GET    /api/demo/impact-analysis/:id        # Multi-hop impact analysis
GET    /api/demo/query-comparison/:id       # Cypher vs SQL comparison
GET    /api/demo/graph-advantage-examples   # Demo scenarios
```

### **WebSocket Events**

```javascript
// Connect to WebSocket
const socket = io('http://localhost:3000');

// Listen for real-time updates
socket.on('job-progress', (data) => {
  console.log('Job progress:', data);
});

socket.on('event-created', (event) => {
  console.log('New event:', event);
});

socket.on('correlation-update', (correlations) => {
  console.log('Correlation update:', correlations);
});
```

### **Request/Response Examples**

#### **Create Configuration Item**
```http
POST /api/cmdb/items
Content-Type: application/json

{
  "name": "Production Web Server 01",
  "type": "Server",
  "properties": {
    "environment": "production",
    "criticality": "HIGH",
    "location": "us-east-1",
    "specifications": {
      "cpu": "8 cores",
      "memory": "32GB",
      "storage": "500GB SSD"
    }
  }
}
```

#### **Start Data Generation**
```http
POST /api/jobs
Content-Type: application/json

{
  "scale": "medium",
  "config": {
    "clearExisting": true,
    "includeEvents": true
  }
}
```

## üîß Technical Details

### **Database Schema**

#### **Node Types**
- **ConfigurationItem**: Core infrastructure components
- **Event**: System events and alerts
- **Service**: Business services
- **BusinessService**: High-level business capabilities

#### **Relationship Types**
- **DEPENDS_ON**: Dependency relationships
- **RUNS_ON**: Hosting relationships
- **HOSTED_IN**: Physical/virtual hosting
- **SUPPORTS**: Service support chains
- **AFFECTS**: Event impact relationships
- **LOCATED_IN**: Geographic relationships

#### **Properties**
```javascript
// Configuration Item
{
  id: "uuid",
  name: "string",
  type: "Server|Database|Application|Service",
  status: "OPERATIONAL|MAINTENANCE|FAILED",
  criticality: "LOW|MEDIUM|HIGH|CRITICAL",
  environment: "DEVELOPMENT|STAGING|PRODUCTION",
  metadata: "object",
  createdAt: "datetime",
  updatedAt: "datetime"
}

// Event
{
  id: "uuid",
  message: "string",
  severity: "INFO|LOW|MEDIUM|HIGH|CRITICAL",
  eventType: "PERFORMANCE|AVAILABILITY|SECURITY|CAPACITY",
  timestamp: "datetime",
  status: "OPEN|ACKNOWLEDGED|RESOLVED",
  correlationScore: "float",
  metadata: "object"
}
```

### **Performance Optimizations**

#### **Query Optimization**
- **Indexed Properties**: id, type, status, criticality
- **Batch Processing**: UNWIND operations for bulk inserts
- **Connection Pooling**: Optimized Neo4j driver configuration
- **Query Caching**: Redis-based result caching

#### **Scalability Features**
- **Horizontal Workers**: Distributed background processing
- **Streaming Responses**: Large dataset pagination
- **Memory Management**: Efficient object recycling
- **Connection Limits**: Controlled database connection usage

### **Technology Stack**

#### **Backend Technologies**
- **Runtime**: Node.js 18+
- **Framework**: Express.js 4.x
- **Database**: Neo4j 5.x Community Edition
- **Cache**: Redis 7.x
- **Queue**: Bull.js with Redis backend
- **WebSockets**: Socket.IO 4.x
- **Logging**: Winston with structured logging

#### **Frontend Technologies**
- **Core**: Vanilla JavaScript (ES6+)
- **Visualization**: D3.js v7
- **UI**: Custom CSS with CSS Grid/Flexbox
- **Real-time**: Socket.IO client
- **Build**: No build process (vanilla JS)

#### **DevOps & Infrastructure**
- **Containerization**: Docker & Docker Compose
- **Process Management**: PM2 (planned)
- **Monitoring**: Custom metrics + Winston logging
- **Health Checks**: Built-in health endpoints

## üß™ Development

### **Project Structure**

```
experimental-cmdb/
‚îú‚îÄ‚îÄ src/                    # Source code
‚îÇ   ‚îú‚îÄ‚îÄ api/               # REST API routes
‚îÇ   ‚îú‚îÄ‚îÄ services/          # Business logic services
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Data models and schemas
‚îÇ   ‚îî‚îÄ‚îÄ utils/             # Utility functions
‚îú‚îÄ‚îÄ public/                # Frontend assets
‚îÇ   ‚îú‚îÄ‚îÄ css/              # Stylesheets
‚îÇ   ‚îú‚îÄ‚îÄ js/               # Client-side JavaScript
‚îÇ   ‚îî‚îÄ‚îÄ index.html        # Main application page
‚îú‚îÄ‚îÄ workers/               # Background processing
‚îú‚îÄ‚îÄ tests/                 # Test suites
‚îÇ   ‚îú‚îÄ‚îÄ unit/             # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ integration/      # Integration tests
‚îÇ   ‚îî‚îÄ‚îÄ e2e/              # End-to-end tests
‚îú‚îÄ‚îÄ docker-compose.yml     # Container orchestration
‚îú‚îÄ‚îÄ package.json           # Dependencies and scripts
‚îú‚îÄ‚îÄ .env.example          # Environment template
‚îî‚îÄ‚îÄ README.md             # This file
```

### **Available Scripts**

```bash
# Development
npm run dev                # Start with auto-reload
npm run demo              # Start demo mode (no database)

# Production
npm start                 # Start production server

# Testing
npm test                  # Run all tests
npm run test:unit         # Unit tests only
npm run test:integration  # Integration tests only
npm run test:e2e          # End-to-end tests

# Database
npm run db:clear          # Clear all data
npm run db:seed           # Load sample data

# Utilities
npm run lint              # Code linting
npm run format            # Code formatting
```

### **Development Guidelines**

#### **Code Style**
- **Linting**: ESLint with Airbnb configuration
- **Formatting**: Prettier for consistent code style
- **Comments**: JSDoc for function documentation
- **Naming**: Descriptive variable and function names

#### **Git Workflow**
```bash
# Feature development
git checkout -b feature/new-feature
git commit -m "feat: add new feature"
git push origin feature/new-feature

# Bug fixes
git checkout -b fix/bug-description
git commit -m "fix: resolve bug description"

# Commit message format
feat: new feature
fix: bug fix
docs: documentation
style: formatting
refactor: code refactoring
test: adding tests
```

#### **API Development**
- **RESTful Design**: Follow REST principles
- **Error Handling**: Consistent error responses
- **Validation**: Input validation for all endpoints
- **Documentation**: OpenAPI/Swagger specs (planned)

## üß™ Testing

### **Test Strategy**

#### **Unit Tests** (`tests/unit/`)
- Individual function testing
- Mock external dependencies
- High code coverage (>80%)

#### **Integration Tests** (`tests/integration/`)
- API endpoint testing
- Database interaction testing
- Service integration testing

#### **End-to-End Tests** (`tests/e2e/`)
- Full user workflow testing
- Browser automation with Puppeteer
- Real environment testing

### **Running Tests**

```bash
# All tests
npm test

# Specific test suites
npm run test:unit
npm run test:integration
npm run test:e2e

# Watch mode
npm run test:watch

# Coverage report
npm run test:coverage
```

### **Test Configuration**

Tests use a separate test environment:
- **Test Database**: Isolated Neo4j instance
- **Test Redis**: Separate Redis instance
- **Mock Data**: Predefined test datasets

## ‚ö° Performance

### **Benchmarks**

#### **Query Performance** (50,000 CIs)
- **Single CI Lookup**: <5ms
- **2-hop Dependencies**: <20ms
- **6-hop Impact Analysis**: <100ms
- **Complex Correlations**: <500ms

#### **Data Generation Performance**
- **10,000 CIs**: ~30 seconds
- **50,000 CIs**: ~2 minutes
- **100,000 CIs**: ~5 minutes

#### **Concurrent Users**
- **Read Operations**: 100+ concurrent users
- **Write Operations**: 50+ concurrent users
- **WebSocket Connections**: 200+ concurrent

### **Optimization Techniques**

#### **Database Optimizations**
```cypher
-- Indexed properties for fast lookups
CREATE INDEX FOR (ci:ConfigurationItem) ON (ci.id)
CREATE INDEX FOR (ci:ConfigurationItem) ON (ci.type)
CREATE INDEX FOR (e:Event) ON (e.timestamp)

-- Optimized queries with LIMIT and filtering
MATCH (ci:ConfigurationItem {type: $type})
WHERE ci.status = 'OPERATIONAL'
RETURN ci
LIMIT 100
```

#### **Caching Strategy**
- **Query Results**: 5-minute TTL for topology data
- **User Sessions**: 24-hour TTL
- **Real-time Data**: 30-second TTL for dashboards

#### **Memory Management**
- **Connection Pooling**: Max 50 connections to Neo4j
- **Batch Processing**: 1000-item batches for large operations
- **Garbage Collection**: Optimized V8 settings

## üîí Security

### **Security Features**

#### **Authentication & Authorization**
- **Environment Variables**: All credentials externalized
- **Session Management**: Secure session handling
- **Input Validation**: Comprehensive request validation
- **CORS Configuration**: Restricted cross-origin requests

#### **Database Security**
- **Parameterized Queries**: Prevention of injection attacks
- **Connection Encryption**: TLS for all database connections
- **Access Control**: Database-level user permissions
- **Audit Logging**: Comprehensive access logging

#### **Application Security**
- **Helmet.js**: Security headers middleware
- **Rate Limiting**: API request throttling
- **HTTPS**: TLS encryption for all communications
- **Security Headers**: CSP, HSTS, and other security headers

### **Security Configuration**

#### **Production Security Checklist**
- [ ] Change all default passwords
- [ ] Enable HTTPS/TLS everywhere
- [ ] Configure firewall rules
- [ ] Set up monitoring and alerting
- [ ] Regular security updates
- [ ] Backup and disaster recovery

#### **Environment Hardening**
```bash
# Docker security
docker run --user 1000:1000 \
  --read-only \
  --tmpfs /tmp \
  --security-opt=no-new-privileges \
  your-app

# Neo4j security
NEO4J_AUTH=neo4j/strong_password_here
NEO4J_dbms_security_auth__enabled=true
```

## üõ†Ô∏è Troubleshooting

### **Common Issues**

#### **Application Won't Start**
```bash
# Check Docker services
docker-compose ps

# View logs
docker-compose logs app
docker-compose logs neo4j

# Check ports
netstat -tlnp | grep :3000
netstat -tlnp | grep :7687
```

#### **Database Connection Issues**
```bash
# Test Neo4j connectivity
curl http://localhost:7474

# Check authentication
docker exec -it neo4j cypher-shell -u neo4j -p password

# Reset Neo4j password
docker-compose down
docker volume rm $(docker volume ls -q | grep neo4j)
docker-compose up -d
```

#### **Performance Issues**
```bash
# Check memory usage
docker stats

# Monitor database queries
# Access Neo4j Browser at http://localhost:7474
# Run: CALL dbms.queryJournal.list()

# Check Redis connections
redis-cli info clients
```

#### **Data Generation Issues**
```bash
# Check worker logs
docker-compose logs worker

# Monitor job queue
redis-cli
> KEYS bull:*

# Check disk space
df -h
```

### **Debug Mode**

Enable debug logging:
```bash
# Set environment variable
DEBUG=cmdb:*

# Or in .env file
NODE_ENV=development
LOG_LEVEL=debug
```

### **Health Checks**

Monitor application health:
```bash
# API health
curl http://localhost:3000/health

# Database health
curl http://localhost:3000/api/cmdb/database/stats

# Worker health
curl http://localhost:3000/api/jobs/stats
```

## üöÄ Future Improvements

This experimental CMDB serves as a foundation for advanced CMDB capabilities. The following enhancements would demonstrate even more sophisticated configuration management features:

### **Enhanced Relationship Modeling**
- **Weighted Edge Relationships**: Implement complex weightings for CI dependencies (e.g., load balancing factors, redundancy levels, criticality scores)
- **Dynamic Relationship Properties**: Support time-varying relationships that change based on load, scaling events, or failover scenarios
- **Conditional Dependencies**: Model relationships that activate only under specific conditions (backup systems, disaster recovery paths)

### **AI-Powered Discovery & Automation**
- **Automated Discovery Engine**: Real-time infrastructure scanning with ML-based component classification
- **Configuration Drift Detection**: Continuous monitoring and alerting for unauthorized changes
- **Predictive Maintenance**: ML models for predicting component failures based on relationship patterns
- **Smart Correlation**: Advanced AI algorithms for pattern recognition in event streams

### **Advanced Analytics & Intelligence**
- **Capacity Planning Models**: Predictive scaling recommendations based on topology analysis
- **Business Service Optimization**: AI-driven suggestions for service architecture improvements
- **Risk Assessment Engine**: Automated security and reliability risk scoring for configuration changes
- **Performance Anomaly Detection**: Graph-based algorithms for identifying unusual system behavior

### **Enterprise Integration Features**
- **Multi-Tenancy Support**: Complete tenant isolation with shared service modeling
- **ITSM Integration**: Deep integration with ServiceNow, Jira Service Management, and other ITSM tools
- **CI/CD Pipeline Integration**: Real-time tracking of infrastructure changes through deployment pipelines
- **Cloud Provider APIs**: Native integration with AWS, Azure, GCP for automated discovery

### **Advanced Visualization & UX**
- **3D Topology Visualization**: Immersive 3D representations of complex infrastructure relationships
- **Augmented Reality Integration**: AR visualization for physical infrastructure management
- **Time-based Topology Animation**: Historical playback of infrastructure evolution
- **Interactive Impact Simulation**: What-if analysis with drag-and-drop scenario modeling

### **Governance & Compliance**
- **Policy Engine**: Rule-based compliance checking with automated remediation
- **Audit Trail Visualization**: Interactive timeline of all configuration changes
- **Compliance Dashboard**: Real-time compliance status across multiple frameworks (SOX, GDPR, HIPAA)
- **Change Approval Workflows**: Integration with approval processes and change advisory boards

### **Security & Threat Modeling**
- **Attack Path Analysis**: Graph-based security vulnerability analysis
- **Zero Trust Architecture Modeling**: Support for modern security paradigms
- **Threat Intelligence Integration**: Real-time threat data correlation with infrastructure topology
- **Security Posture Scoring**: Automated security assessment based on configuration analysis

### **Advanced Event Processing**
- **Complex Event Processing (CEP)**: Pattern matching across multiple event streams
- **Machine Learning Correlation**: Self-learning correlation engines that improve over time
- **Federated Event Sources**: Integration with multiple monitoring and logging systems
- **Event Stream Analytics**: Real-time processing of high-volume event streams

### **Scale & Performance Enhancements**
- **Distributed Graph Database**: Multi-node Neo4j clusters for enterprise scale
- **Event Streaming Architecture**: Kafka-based event processing for high throughput
- **Microservices Architecture**: Decomposed services for independent scaling
- **Global Distribution**: Multi-region deployment with data synchronization

### **Developer Experience**
- **GraphQL API**: Modern API layer for flexible data querying
- **SDK Development**: Client libraries for popular programming languages
- **Plugin Architecture**: Extensible framework for custom integrations
- **Low-Code Configuration**: Visual configuration tools for non-technical users

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### **Development Process**

1. **Fork** the repository
2. **Create** a feature branch
3. **Make** your changes
4. **Add** tests for new functionality
5. **Ensure** all tests pass
6. **Submit** a pull request

### **Code Quality**

- Follow existing code style
- Add comprehensive tests
- Update documentation
- Ensure backward compatibility

### **Reporting Issues**

When reporting issues, please include:
- Operating system and version
- Node.js version
- Docker version
- Steps to reproduce
- Expected vs actual behavior
- Log files and error messages

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **Neo4j Community** for excellent graph database technology
- **D3.js Team** for powerful visualization capabilities
- **Node.js Community** for robust ecosystem
- **Docker** for containerization platform

## üìû Support

- **Documentation**: This README and inline code comments
- **Issues**: GitHub Issues for bug reports and feature requests
- **Discussions**: GitHub Discussions for questions and community
- **Email**: [Insert contact email]

---

**Built with ‚ù§Ô∏è for the future of IT infrastructure management**